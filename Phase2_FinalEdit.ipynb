{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # for capturing video using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for using directory navigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d31aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr # used for face recognition modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npy #used for organising the data in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # for displaying the data collected using camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd332fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this xml file was taken from # https://github.com/kipr/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8367393",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f48b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined function to apply the image resizing on the frames that are captured\n",
    "\n",
    "def filteredloop(loop_data,tempdata):\n",
    "    for x,y,w,h in loop_data:# x,y cordinates and width and height of the image\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,255), 4) # to display rectangle over the identified image that takes x,y cordinates and width and height as parameters\n",
    "        updated_frame = frame[y:y+h, x:x+w, :]# rows and columns of the face detected in the frame\n",
    "        updated_frame = cv2.resize(updated_frame, (50,50))#resizing all the identified faces in the frame to standard 50*50 size\n",
    "        print(len(tempdata))\n",
    "        if len(tempdata) < 200:#loop for capturing 200 frames and storing them\n",
    "             tempdata.append(updated_frame)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_mask_data = [] # to store the data of the images without having mask\n",
    "capture = cv2.VideoCapture(0)#to turn on the camera module\n",
    "while True:\n",
    "    #isflagTrue contains true or false. read() returns true to this variable if the camera module is working fine\n",
    "    \n",
    "    isflagTrue , frame = capture.read()#to input the frames from the camera module\n",
    "    if(isflagTrue):\n",
    "        currentframe = traindata.detectMultiScale(frame)#perfroms sliding window operation and detects the haar features in every window. This line detects the faces in the current image frame\n",
    "        filteredloop(currentframe,without_mask_data)\n",
    "        cv2.imshow('result',frame)\n",
    "        # ascii value of letter \"q\" is 2. if user clicks \"q\", the loop will be terminated\n",
    "        if cv2.waitKey(2) == 113 or len(without_mask_data) >= 200:\n",
    "            break\n",
    "    \n",
    "capture.release()# release the camera module\n",
    "cv2.destroyAllWindows() # to close the popup camera window\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7193f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy.save('nomask.npy',without_mask_data)# saving the results in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ade3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module to capture data with mask\n",
    "\n",
    "mask_data = [] # to store the data of the images having mask\n",
    "capture = cv2.VideoCapture(0) #to turn on the camera module\n",
    "while True:\n",
    "    isflagTrue , frame = capture.read() #isflagTrue contains true or false. read() returns true to this variable if the camera module is working fine\n",
    "    if(isflagTrue):\n",
    "        currentframe = traindata.detectMultiScale(frame)\n",
    "        filteredloop(currentframe,mask_data)\n",
    "        cv2.imshow('result',frame)\n",
    "        if cv2.waitKey(2) == 113 or len(mask_data) >= 200:#the loop terminates when user clicks \"q\" or when it completes taking 200 pics\n",
    "            break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0922d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy.save('mask.npy',mask_data)#saving the details in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_data[116]) # to show a random file in the data captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88068091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data from the files\n",
    "mask = npy.load('mask.npy')\n",
    "nomask = npy.load('nomask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a73437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert the data in the files into 2D images\n",
    "def reshape(data):\n",
    "    return data.reshape(200,50 * 50 *3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data using the user-defined function\n",
    "mask = reshape(mask)\n",
    "nomask = reshape(nomask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cefde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the data together to a single dataset using concatination\n",
    "combined_data = npy.r_[mask, nomask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the first 200 dataset values in the combined dataset to 0 and the rest 200 values to 1\n",
    "indexes = npy.zeros(combined_data.shape[0])\n",
    "indexes[200:] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/\n",
    "#https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC #to load the linear support vector classifier from sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # predefined function to split the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y1, y2 = train_test_split(combined_data,indexes, test_size=0.25)#To prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3) #principal component analysis to reduce the linear dimensity  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pca.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ad7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, y1, y2 = train_test_split(combined_data,indexes, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f202e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7defc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedvalue = svm.predict(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y2, predictedvalue) #getting the accuracy over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a99158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to display the values Mask and No mask on the rectangle over the image\n",
    "values = {0 : 'Mask', 1 : 'No Mask'}\n",
    "f_style = cv2.FONT_HERSHEY_COMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da405c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined function to resize the images to standard 50*50\n",
    "def adjustframe(frame):\n",
    "    adjustedframe = frame[y:y+h, x:x+w, :]\n",
    "    adjustedframe = cv2.resize(adjustedframe, (50,50))\n",
    "    adjustedframe = adjustedframe.reshape(1,-1)\n",
    "    return svm.predict(adjustedframe)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined function for loading images from designated Directory\n",
    "images = []#array for storing the images\n",
    "c_names = []#array for storing the names of the images\n",
    "myList = os.listdir(\"ai_testimages\")#loading the names of the images\n",
    "myList.remove(\".ipynb_checkpoints\")#removing the temp file that was created by default by Jupyter Notebook\n",
    "print(myList)\n",
    "#loading the images from the designated directory to the images array\n",
    "for i in myList:\n",
    "    currentImg = cv2.imread(f'{\"ai_testimages\"}/{i}')\n",
    "    images.append(currentImg)\n",
    "    c_names.append(os.path.splitext(i)[0])#saving the names of the image files\n",
    "print(c_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the images from the designated path\n",
    "f_encode = []\n",
    "img_encoding = []\n",
    "for i in myList:\n",
    "    Img = fr.load_image_file(f'{\"ai_testimages\"}/{i}')\n",
    "    img_encoding.append(fr.face_encodings(Img)[0])\n",
    "print(img_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable initialisation \n",
    "f_loc = []\n",
    "f_encode = []\n",
    "f_names = []\n",
    "p_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined function for encoding the images from the designated directory\n",
    "def encode(f_encode):\n",
    "    for i in f_encode:\n",
    "        cr_match = fr.compare_faces(img_encoding, i)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        face_dist = fr.face_distance(img_encoding, i)\n",
    "        b_m_i = npy.argmin(face_dist)\n",
    "        if cr_match[b_m_i]:\n",
    "            name = c_names[b_m_i]\n",
    "\n",
    "        f_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93145aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined function to display the result\n",
    "def result(cresult):\n",
    "     for (t, r, b, l), name in cresult:\n",
    "        t *= 4\n",
    "        r *= 4\n",
    "        b *= 4\n",
    "        l *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (l, b - 35), (r, b), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(frame, name, (l + 6, b - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, result1, (l + 6, t - 6), font, 1.0, (255, 255, 255), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#module to start the live detection\n",
    "traindata = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "capture = cv2.VideoCapture(0) #for capturing the video frame\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "data = []\n",
    "result1 =\"\"\n",
    "cresult =\"\"\n",
    "while(1):\n",
    "    isFlagTrue, frame = capture.read()\n",
    "    if(isFlagTrue):\n",
    "        currentframe = traindata.detectMultiScale(frame)\n",
    "        for x,y,w,h in currentframe:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,255), 4)# to display rectangle over the identified image that takes x,y cordinates and width and height as parameters\n",
    "            result1 = values[int(adjustframe(frame))]# converting the \n",
    "            #cv2.putText(frame, result, (x,y), f_style, 1, (244,250,250), 2) #to show the results over the rectangle \"Mask\", \"No Mask\"\n",
    "            print(result1) # to print the result\n",
    "        # Removed as a part of phase 2\n",
    "        #cv2.imshow('result',frame)\n",
    "        #result1=result\n",
    "        #if cv2.waitKey(33) & 0xFF == ord('q'):## to terminate the loop when the user clicks \"q\"\n",
    "         #   break\n",
    "\n",
    " \n",
    "    #phase II:\n",
    "    ret, frame = video_capture.read() #to capture a frame\n",
    "\n",
    "    # Resizing the image \n",
    "    s_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    \n",
    "    # Converting the video frame to standard input image used by face recognition\n",
    "    r_frame = s_frame[:, :, ::-1]\n",
    "    \n",
    "    if p_frame:\n",
    "        f_loc = fr.face_locations(r_frame)\n",
    "        f_encode = fr.face_encodings(r_frame, f_loc)\n",
    "        f_names = []\n",
    "        encode(f_encode)     \n",
    "    p_frame = not p_frame\n",
    "    # Display the results\n",
    "    cresult = zip(f_loc, f_names)\n",
    "    \n",
    "    result(cresult)\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video',frame)\n",
    "    #cv2.imshow('result1',frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0484b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c9541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78812b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf65c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
